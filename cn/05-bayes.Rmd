# Bayes'sche Ansätze {#bayes}
```{r KnitrOptsChunkEvalTrue, echo=FALSE, results='hide'} 
# resetting evaluation to true
knitr::opts_chunk$set(eval = TRUE)
```

```{r BayesAbbrev, echo=FALSE, results='hide'}
r6objTableAbbrev$add_abbrev(psAbbrev = "REML", psMeaning = "Restricted oder Residual Maximum Likelihood", pbOut = FALSE)
r6objTableAbbrev$add_abbrev(psAbbrev = "ML", psMeaning = "Maximum Likelihood", pbOut = FALSE)
r6objTableAbbrev$add_abbrev(psAbbrev = "MCMC", psMeaning = "Markov Chain Monte Carlo", pbOut = FALSE)
```


## Einführung
In der Statistik gibt es zwei verschiedene Lehrmeinungen. Diese unterscheiden sich vor allem in deren philosophischen Verständnis des Begriffs der __Wahrscheinlichkeit__. 

* Für die __Frequentisten__ ist die Wahrscheinlichkeit im wesentlichen ein Häufigkeitsmass, welche angibt welches Ereignis wie häufig oder mit welcher Frequenz auftritt.
* __Bayesianer__ verwenden die Wahrscheinlichkeit um die Sicherheit oder die Unsicherheit für ein Ereignis zu quantifizieren. Dabei sind diese Einschätzungen von Sicherheit oder Unsicherheit auch immer subjektiv, was ein sehr starker Kritikpunkt der Bayes'schen Methoden darstellt. 

Alle bisher \footnote{Hier ist nicht nur diese Vorlesung sondern auch die Züchtungslehre und die angewandet Zuchtwertschätzung gemeint} vorgestellten statistischen Konzepte, so zum Beispiel `Least Squares`, `Maximum Likelihood`, `REML` und `BLUP` stammen aus dem Lager der Frequentisten.

Die für die praktischen Analysen relevanten Unterschiede zwischen Frequentisten und Bayesianern bestehen hauptsächlich in 

- deren Verständnis von Wahrscheinlichkeiten
- deren Unterteilung von Modell- und Datenkomponenten
- deren Techniken zur Schätzung von Parametern

Die folgende Tabelle gibt eine Übersicht über die Unterschiede.

```{r FreqBayesTable, eval=TRUE, echo=FALSE, results='asis'}
Was <- c("Wahrscheinlichkeiten", "Modelle und Daten", "Schätztung der Parameter")
Frequentisten <- c("Verhältnis zwischen Kardinalitäten von Mengen",
                   "Parameter sind unbekannt, Daten sind bekannt",
                   "ML oder REML werden für Parameterschätzung verwendet")
Bayesianer <-  c("Mass für Informationsgehalt unabhängig von Stichprobengrösse",
                 "Unterscheidung zwischen unbekannten und bekannten Grössen",
                 "MCMC Zufallszahlen zur Approximation der gewünschten a posteriori Verteilungen")
dfTabCaptOut <- data.frame(Was           = Was,
                           Frequentisten = Frequentisten,
                           Bayesianer    = Bayesianer,
                           stringsAsFactors = FALSE)
knitr::kable(dfTabCaptOut, format = "latex", align = c("p{3cm}","p{6cm}","p{6cm}"))
```



## Das Lineare Modell
Die Bayes'sche Art der Parameterschätzung soll an einem einfachen linearen Modell gezeigt werden. Angenommen, wir betrachten das Modell

\begin{equation}
y_i = \beta_0 + \beta_1 x_{i1} + \epsilon_i
\label{eq:BayLinMod}
\end{equation}

wobei $y_i$ die $i$-te Beobachtung einer Zielgrösse ist, $\beta_0$ für den Achsenabschnitt steht, $x_1$ eine erklärende Variable ist und $\epsilon_i$ für den Restterm steht. Für die Restterme nehmen wir an, dass deren Varianz konstant gleich $\sigma^2$ ist.


### Bekannte und Unbekannte
Unter der Annahme, dass wir für die Zielgrösse $y_i$ und die erklärende Variable $x_1$ keine fehlenden Daten haben, dann machen wir als Bayesianer folgende Einteilung in bekannte und unbekannte Grössen. 

 und  als __bekannte__ Grössen
```{r BayesianUnKnowsTab, eval=FALSE, echo=FALSE}
Was <- c("$y_i$", "$x_1$", "$\\beta_0$", "$\\beta_1$", "$\\sigma^2$")
bekannt <- c("X", "X", "", "", "X")
unbekannt <- c("", "", "X", "X", "")
knitr::kable(data.frame(Was = Was,
                        bekannt = bekannt,
                        unbekannt = unbekannt, 
                        row.names = NULL,
                        stringsAsFactors = FALSE))
```

\begin{center}
\begin{tabular}{p{3cm}cc}
\hline
Was         &  bekannt  &  unbekannt \\
\hline
$y_i$       &    X      & \\
$x_1$       &    X      & \\
$\beta_0$   &           &      X \\
$\beta_1$   &           &      X \\
$\sigma^2$  &           &      X \\
\hline
\end{tabular}
\end{center}

### Vorgehen bei Parameterschätzung
Bayesianer basieren Schätzungen von unbekannten Grössen auf der sogenannten __a posteriori Verteiung__ der unbekannten Grössen gegeben die bekannten Grössen. Die a posteriori Verteilung wird mithilfe des __Satzes von Bayes__ aufgrund der a priori Verteilung der unbekannten und aufgrund der Likelihood berechnet. 

Die Bezeichnungen "a priori"  und "a posteriori" beziehen sich immer auf den Zeitpunkt der Beobachtung der analysierten Daten. Die jeweiligen Verteilungen quantifizieren den Informationsstand zu den Unbekannten um jeweiligen Zeitpunkt. Dieses Konzept soll anhand der folgenden Grafik verdeutlicht werden.

```{r AprioriAposteriori, echo=FALSE, conv.odg=TRUE, odg.path="odg", odg.graph.cache=TRUE,fig.align='center', out.width='8cm'}
knitr::include_graphics(path = "png/AprioriAposteriori.pdf")
```

Für unser Beispiel des einfachen linearen Modells, definieren wir zuerst den Vektor $\mathbf{\beta}$ als 

$$\beta = \left[\begin{array}{c} \beta_0  \\  \beta_1 \end{array} \right].$$

Die Beobachtungen $y_i$ fassen wir ebenfalls zu einem Vektor $y$ zusammen. Für unser aktuelles Beispiel nehmen wir an, dass $\sigma^2$ bekannt sei. Deshalb lassen wir die Restvarianz auch bei der folgenden Herleitung weg. Eine Bayes'sche Parameterschätzung für $\beta$ basiert dann auf der a posteriori Verteilung $f(\beta | y)$ der Unbekannten $\beta$ gegeben die Bekannte Grösse $y$. Diese a posteriori Verteilung lässt sich mit dem Satz von Bayes, wie folgt berechnen

\begin{eqnarray}
f(\beta | y) & =       & \frac{f(\beta, y)}{f(y)} \nonumber \\
             & =       & \frac{f(y | \beta)f(\beta)}{f(y)} \nonumber \\
                       & \propto & f(y | \beta)f(\beta)
\label{LinModAPostProb}
\end{eqnarray}

In Gleichung (\ref{LinModAPostProb}) konnten wir die a posteriori Verteilung $f(\beta | y)$ als Produkt der a priori Verteilung ($f(\beta)$) der unbekannten Grösse $\beta$ und der Likelihood $f(y | \beta)$ ausdrücken. Der Faktor $f(y)^{-1}$ (Term im Nenner) entspricht der sogenannten Normalisierungskonstanten und ist nicht weiter von Interesse. Somit wird die a posteriori Verteilung oft als Proporzionalitätsbeziehung angegeben. 

Die a posteriori Verteilung $f(\beta | y)$ ist in vielen Fällen nicht explizit darstellbar. Das war lange ein Problem, welches die Anwendung von Bayes'schen Analysen sehr einschränkte. Zwei Entwicklungen haben dieses Problem beseitigt.

1. Im Paper (@Besa1974) zeigte Julian Besag, dass jede a posteriori Verteilung durch eine Serie von Zufallszahlen aus den voll-bedingten Verteilungen bestimmt ist. Für unser Beispiel lauten die voll-bedingten Verteilungen: Bedingte Verteilung von $\beta_0$ gegeben alle anderen Grössen: $f(\beta_0 | \beta_1, y)$, bedingte Verteilung von $\beta_1$ gegeben alle anderen Grössen: $f(\beta_1 | \beta_0, y)$.
2. Die Entwicklung von effizienten Pseudo-Zufallszahlen-Generatoren auf dem Computer.


## Gibbs Sampler
Die Umsetzung der beiden oben aufgelisteten Punkte führt zu einer Prozedur, welche als __Gibbs Sampler__ bezeichnet wird. Wenden wir den Gibbs Sampler auf einfaches lineares Regressionsmodell an, dann resultiert das folgende Vorgehen bei der Analyse. Unabhängig vom verwendeten Modell läuft die Konstruktion einer Gibbs Sampling Prozedur immer in den folgenden Schritten ab. Diese Schritte können für die meisten Analysen wie ein Kochbuchrezept verwendet werden.

1. Bestimmung der a priori Verteilungen für die unbekannten Grössen. 
2. Bestimmung der Likelihood
3. Bestimmung der voll-bedingten Verteilungen

### A priori Verteilungen
In unserem Bespiel handelt es sich dabei um $f(\beta)$. In den meisten Fällen, wenn man das erste Mal eine bestimmte Art von Daten analysisern soll, empfielt es sich eine sogenannte uniformative a priori Verteilung zu wählen. Eine uninformative a priori Verteilung bedeutet einfach, dass deren Dichtewert überall gleich, also eine Konstante ist. Wenden wir zum Beispiel für die Unbekannte $\beta$  eine uninformative a priori Verteilung an, dann bedeutet das, dass wir $f(\beta) = c$. 

Alternativ zu der uniformativen a priori Verteilung gibt es auch a priori Verteiungen für bestimmte unbekannte Grössen, welche als de-facto Standard aktzeptiert sind. Ein Bespiel dafür wäre, wenn die Restvarianz unbekannt ist, würde man deren a priori Verteilung mit einer Inversen-Chi-Quadrat Verteilung modellieren.   


### Likelihood
Die Likelihood ist wie bei den Frequentisten als begingte Verteilung ($f(y | \beta)$) der Daten $y$ gegeben die Parameter ($\beta$). Falls keine Daten fehlen, dann ist die Bayes'sche Likelihood und die frequentistische Likelihood gleich.


### Vollbedingte Verteilungen
Mit vollbedingten Verteilungen ist gemeint, dass für jede unbekannte Grösse die bedingte Verteilung gegeben alle anderen Grössen bestimmt wird. In unserem Bespiel des linearen Regressionsmodells haben wir zwei unbekannte Grössen $\beta_0$ und $\beta_1$. Somit haben wir auch zwei vollbedingte Verteilungen. Unter der Annahme, dass unsere Daten ($y$) einer Normalverteilung folgen, resultieren die folgenden vollbedingten Verteilungen.

\vspace{2ex}
```{r FullCondTable, eval=FALSE, echo=FALSE}
dfFullCond <- data.frame(unknown = c("$\\beta_0$","$\\beta_1$","$\\sigma^2$"),
                         fullcond = c("$f(\\beta_0 | \\beta_1, \\sigma^2, \\mathbf{y})$",
                                      "$f(\\beta_1 | \\beta_0, \\sigma^2, \\mathbf{y})$",
                                      "$f(\\sigma^2 | \\beta_0, \\beta_1, \\mathbf{y})$"),
                         result = c("$\\mathcal{N}(\\hat{\\beta}_0, var(\\hat{\\beta}_0))$",
                                    "$\\mathcal{N}(\\hat{\\beta}_1, var(\\hat{\\beta}_1))$",
                                    "$\\propto \\chi^{-2}$"))
names(dfFullCond) <- c("unbekannte Grösse", "vollbedingte Verteilung", "resultierende Verteilung")
knitr::kable(dfFullCond)
```

\begin{center}
\begin{tabular}{lll}
\hline
unbekannte Grösse  &  unbekannte Grösse                    &  resultierende Verteilung \\
\hline
$\beta_0$          &  $f(\beta_0 | \beta_1, y)$  &  $\mathcal{N}\left(\hat{\beta}_0, var(\hat{\beta}_0)\right)$ \\
$\beta_1$          &  $f(\beta_1 | \beta_0, y)$  &  $\mathcal{N}\left(\hat{\beta}_1, var(\hat{\beta}_1)\right)$ \\
\hline
\end{tabular}
\end{center}


Aufgrund von Berechnungen, welche hier nicht gezeigt sind, können wir die oben aufgelisteten vollbedingten Verteilungen bestimmen. Die entsprechenden Verteilungen sind in der Kolonnen ganz rechts, welche mit "resultierende Verteilung" überschrieben ist, aufgelistet. Dabei steht $\mathcal{N}()$ für die Normalverteilung. Für die Erwartungswerte und Varianzen wird das Modell in Gleichung (\ref{eq:BayLinMod}) leicht umformuliert.

\begin{equation}
\mathbf{y} = \mathbf{1}\beta_0 + \mathbf{x}\beta_1 + \mathbf{\epsilon}
\label{eq:BayLinModReform}
\end{equation}

Aus dem obigen Modell bilden wir ein neues Modell, welches auf der rechten Seite der Gleichung nur von $\beta_0$ und $\mathbf{\epsilon}$ abhängt. Da wir wissen, dass die Verteilung der Least Squares Schätzer eine Normalverteilung ist, werden wir diese für die Bestimmung der vollbedingten Verteilungen verwenden.

\begin{equation}
\mathbf{w}_0 = \mathbf{1}\beta_0 + \mathbf{\epsilon}
\label{eq:BayLinModW0}
\end{equation}

wobei $\mathbf{w}_0 = \mathbf{y} - \mathbf{x}\beta_1$. Aufgrund des Modells in Gleichung (\ref{eq:BayLinModW0}) können wir den Least Squares Schätzer für $\beta_0$ aufstellen. Dieser lautet:

\begin{equation}
\hat{\beta}_0 = (\mathbf{1}^T\mathbf{1})^{-1}\mathbf{1}^T\mathbf{w}_0
\label{eq:Beta0LsEst}
\end{equation}

Die Varianz des Least Squares Schätzers für $\beta_0$ lautet:

\begin{equation}
var(\hat{\beta}_0) = (\mathbf{1}^T\mathbf{1})^{-1}\sigma^2
\label{eq:VarBeta0LsEst}
\end{equation}

Analog zu $\beta_0$ berechnen wir den Least Squares Schätzer für $\beta_1$ und dessen Varianz.

\begin{equation}
\hat{\beta}_1 = (\mathbf{x}^T\mathbf{x})^{-1}\mathbf{x}^T\mathbf{w}_1
\label{eq:Beta1LsEst}
\end{equation}

wobei $\mathbf{w}_1 = \mathbf{y} - \mathbf{1}\beta_0$

\begin{equation}
var(\hat{\beta}_1) = (\mathbf{x}^T\mathbf{x})^{-1}\sigma^2
\label{eq:VarBeta1LsEst}
\end{equation}


### Umsetzung des Gibbs Samplers
Der Gibbs Sampler wird durch wiederholtes ziehen von Zufallszahlen aus den oben angegebenen vollbedingten Verteilungen umgesetzt. Das heisst, wir setzen für alle unbekannten Grössen sinnvolle Startwerte ein. Für $\beta_0$ und $\beta_1$ wählen wir $0$ als Startwert. Dann berechnen wir den Erwartungswert und die Varianz für die vollbedingte Verteilung von $\beta_0$. Aus dieser Verteilung ziehen wir einen neuen Wert für $\beta_0$. In einem zweiten Schritt berechnen wir den Erwartungswert und die Varianz für die vollbedingte Verteilung von $\beta_1$, wobei wir für $\beta_0$ schon den neuen Wert einsetzen. Aus der Verteilung für $\beta_1$ ziehen wir einen neuen Wert für $\beta_1$. Danach beginnen wir die Schritte wieder bei $\beta_0$. Diese Schrittabfolge wiederholen wir $10000$ mal und speichern alle gezogenen Werte für $\beta_0$ und $\beta_1$. Die Bayes'schen Parameterschätzungen entsprechen dann den Mittelwerten der gespeicherten Werte.

Der folgende R-Codeblock soll die Umsetzung des Gibbs Samplers für $\beta_0$ und $\beta_1$ als Programm zeigen. Der Einfachheit halber wurde $\sigma^2$ konstant $\sigma^2=1$ angenommen.

```{r RGibbsSampler, eval=FALSE, echo=TRUE}
# ### Startwerte für beta0 und beta1
beta <– c(0, 0)
# ### Bestimmung der Anzahl Iterationen
niter <– 10000
# ### Initialisierung des Vektors mit Resultaten
meanBeta <– c(0, 0)
for (iter in 1:niter) {
  # Ziehung des Wertes des Achsenabschnitts beta0
  w <– y - X[, 2] * beta[2]
  x <– X[, 1]
  xpxi <– 1/(t(x) %*% x)
  betaHat <– t(x) %*% w * xpxi
  # ### neue Zufallszahl fuer beta0
  beta[1] <– rnorm(1, betaHat, sqrt(xpxi))
  # Ziehung der Steigung beta1
  w <– y - X[, 1] * beta[1]
  x <– X[, 2]
  xpxi <– 1/(t(x) %*% x)
  betaHat <– t(x) %*% w * xpxi
  # ### neue Zufallszahl fuer beta1
  beta[2] <– rnorm(1, betaHat, sqrt(xpxi))
  meanBeta <– meanBeta + beta
}
# ### Ausgabe der Ergebnisse
cat(sprintf("Achsenabschnitt = %6.3f \n", meanBeta[1]/iter))
cat(sprintf("Steigung = %6.3f \n", meanBeta[2]/iter))

```
